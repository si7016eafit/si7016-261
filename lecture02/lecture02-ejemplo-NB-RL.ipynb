{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvB5NTp4DxAw"
   },
   "source": [
    "# SI7016 Applied NLP, 2026-1\n",
    "# Lecture 02\n",
    "# Classifiers: Naive Bayes and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1753219993394,
     "user": {
      "displayName": "Edwin Nelson Montoya",
      "userId": "10708817807819244709"
     },
     "user_tz": 300
    },
    "id": "7uZwoRef6FXU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1753219996267,
     "user": {
      "displayName": "Edwin Nelson Montoya",
      "userId": "10708817807819244709"
     },
     "user_tz": 300
    },
    "id": "WBhddUsA6AjR"
   },
   "outputs": [],
   "source": [
    "# reviews de peliculas\n",
    "texts = [\n",
    "    \"Me encantó la película, muy buena\",\n",
    "    \"Una historia excelente y conmovedora\",\n",
    "    \"Pésima, no la recomiendo\",\n",
    "    \"Actuación muy mala y aburrida\",\n",
    "    \"Gran producción y buen guión\",\n",
    "    \"Una pérdida de tiempo, muy lenta\",\n",
    "    \"Maravillosa, la volvería a ver\",\n",
    "    \"Demasiado predecible y sin emoción\"\n",
    "]\n",
    "labels = [1, 1, 0, 0, 1, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nZQEPDm9mN_"
   },
   "source": [
    "# Representación del texto: BoW vs TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1753219999733,
     "user": {
      "displayName": "Edwin Nelson Montoya",
      "userId": "10708817807819244709"
     },
     "user_tz": 300
    },
    "id": "Fg00199432A_"
   },
   "outputs": [],
   "source": [
    "tvectorizer = TfidfVectorizer()\n",
    "Xtfidf = tvectorizer.fit_transform(texts)\n",
    "\n",
    "cvectorizer = CountVectorizer()\n",
    "Xbow = cvectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1753220001983,
     "user": {
      "displayName": "Edwin Nelson Montoya",
      "userId": "10708817807819244709"
     },
     "user_tz": 300
    },
    "id": "Mq8Lf6Jw3-y3",
    "outputId": "dc84e6ec-33da-47cf-ffc1-5bbb5d8c1007"
   },
   "outputs": [],
   "source": [
    "# matriz de características TFIDF\n",
    "print(Xtfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1753220005475,
     "user": {
      "displayName": "Edwin Nelson Montoya",
      "userId": "10708817807819244709"
     },
     "user_tz": 300
    },
    "id": "JsdvXoye4pZY",
    "outputId": "a5cffc90-a7f5-4916-b9e5-af679653bc97"
   },
   "outputs": [],
   "source": [
    "# matriz de características BoW\n",
    "print(Xbow.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reto corto:\n",
    "\n",
    "- Con el mismo corpus, crea TF-IDF con bigramas (1,2) y compara:\n",
    "- tamaño del vocabulario\n",
    "- 5 términos con mayor peso en un documento positivo y uno negativo\n",
    "\n",
    "- Pregunta: ¿qué bigramas capturan mejor sentimiento que unigramas?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1FZsmQt9xoc"
   },
   "source": [
    "# Classifier: movie reviews with NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1753220008776,
     "user": {
      "displayName": "Edwin Nelson Montoya",
      "userId": "10708817807819244709"
     },
     "user_tz": 300
    },
    "id": "FY_C5ld08tDi",
    "outputId": "9fd80dbc-96c7-4bb3-a60c-5e40c6b5e5c9"
   },
   "outputs": [],
   "source": [
    "#  pipeline: TF-IDF + clasificador Naive Bayes\n",
    "pipelineNB = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Entrenar modelo\n",
    "pipelineNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3rgNtTe9BZM"
   },
   "outputs": [],
   "source": [
    "# evaluación del modelo NB\n",
    "# Predicción\n",
    "y_pred = pipelineNB.predict(X_test)\n",
    "\n",
    "# Reporte de clasificación NB\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSQwYXFW9TOv"
   },
   "outputs": [],
   "source": [
    "# Clasificar nuevos reviews de peliculas con modelo NB\n",
    "nuevas_opiniones = [\n",
    "    \"Fue una película muy inspiradora\",\n",
    "    \"No me gustó, muy aburrida\",\n",
    "    \"Una experiencia buena y emotiva\"\n",
    "]\n",
    "\n",
    "# Predicción\n",
    "predicciones = pipelineNB.predict(nuevas_opiniones)\n",
    "for texto, pred in zip(nuevas_opiniones, predicciones):\n",
    "    print(f\"\\nOpinión: '{texto}'\\nSentimiento predicho: {'Positivo' if pred == 1 else 'Negativo'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reto corto\n",
    "- usa datasets con datos más grandes, ej: UCI/Yelp, news-reuters, etc\n",
    "- Entrena dos variantes de NB:\n",
    "* CountVectorizer() + MultinomialNB()\n",
    "* TfidfVectorizer() + MultinomialNB()\n",
    "- Pregunta: ¿cuál generaliza mejor en el dataset UCI/Yelp?\n",
    "- Explica el resultado conectándolo con “conteos” vs “reponderación”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64m1OB54-PqS"
   },
   "source": [
    "# Classifier: movie reviews with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RU9zXUiH5yxe"
   },
   "outputs": [],
   "source": [
    "# entrenar el modelo de RL\n",
    "\n",
    "# Definir pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Entrenar modelo\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95jpIA1V7Ku6"
   },
   "outputs": [],
   "source": [
    "# evaluación del modelo RL\n",
    "# Predicción\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Reporte de clasificación\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbwdgiPg7VJs"
   },
   "outputs": [],
   "source": [
    "# Clasificar nuevos reviews de peliculas con modelo RL\n",
    "nuevas_opiniones = [\n",
    "    \"Fue una película muy inspiradora\",\n",
    "    \"No me gustó, muy aburrida\",\n",
    "    \"Una experiencia buena y emotiva\"\n",
    "]\n",
    "\n",
    "# Predicción\n",
    "predicciones = pipeline.predict(nuevas_opiniones)\n",
    "for texto, pred in zip(nuevas_opiniones, predicciones):\n",
    "    print(f\"\\nOpinión: '{texto}'\\nSentimiento predicho: {'Positivo' if pred == 1 else 'Negativo'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reto corto:\n",
    "\n",
    "- En RL, prueba:\n",
    "- unigramas vs bigramas (1,2)\n",
    "- C=0.1, 1, 10 (regularización)\n",
    "- Pregunta: ¿qué cambia más el desempeño: n-grams o regularización? ¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfxdmfzk-Y5T"
   },
   "source": [
    "# SUPER RETO\n",
    "# usar datasets de YELP etiquetados\n",
    "# y adapte los clasificadores de NB y RL para entrenar, validar, y predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5PS0fei-hTj"
   },
   "outputs": [],
   "source": [
    "# URL del archivo en el repositorio UCI\n",
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "\n",
    "# 1. URL del archivo ZIP de UCI\n",
    "zip_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip\"\n",
    "zip_filename = \"sentiment_labelled_sentences.zip\"\n",
    "extract_dir = \"sentiment_data\"\n",
    "\n",
    "# 2. Descargar el archivo zip si no existe\n",
    "if not os.path.exists(zip_filename):\n",
    "    print(\"Descargando archivo ZIP...\")\n",
    "    urllib.request.urlretrieve(zip_url, zip_filename)\n",
    "    print(\"Descarga completada.\")\n",
    "\n",
    "# 3. Descomprimir el archivo zip\n",
    "if not os.path.exists(extract_dir):\n",
    "    print(\"Descomprimiendo archivo ZIP...\")\n",
    "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(\"Descompresión completada.\")\n",
    "\n",
    "# 4. Leer el archivo yelp_labelled.txt\n",
    "yelp_path = os.path.join(extract_dir, \"sentiment labelled sentences\", \"yelp_labelled.txt\")\n",
    "\n",
    "df_yelp = pd.read_csv(yelp_path, sep=\"\\t\", header=None, names=[\"text\", \"label\"])\n",
    "\n",
    "# 5. Mostrar primeras filas\n",
    "print(\"Primeras filas del DataFrame:\")\n",
    "print(df_yelp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realiza sobre el super reto:\n",
    "\n",
    "- En Yelp:\n",
    "- Entrena NB y RL con TF-IDF unigramas\n",
    "- Reporta F1 (macro) y matriz de confusión\n",
    "- Muestra 3 ejemplos donde NB falla y RL acierta (y viceversa)\n",
    "- Pregunta: ¿qué patrón lingüístico explica esos errores? (negación, ironía, adjetivos raros, expresiones compuestas, etc.)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNdK+PvxtLSRY3izg6yHBE8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
